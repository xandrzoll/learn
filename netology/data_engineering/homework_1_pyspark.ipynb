{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EL8PbPL2J1PU"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "from pyspark import SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "def get_spark_context(app_name: str):\n",
        "    conf = SparkConf()\n",
        "    \n",
        "    conf.setAll(\n",
        "        [\n",
        "            ('spark.master', 'spark://spark-master:7077'),\n",
        "            ('spark.driver.host', 'local[*]'),\n",
        "            ('spark.submit.deployMode', 'client'),\n",
        "            ('spark.driver.bindAddress', '192.168.0.15'),\n",
        "            ('spark.app.name', app_name),\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    return SparkSession.builder.config(conf=conf).getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = get_spark_context('netology')"
      ],
      "metadata": {
        "id": "a_DK7Di-J4hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "выше возникает какая-то беда при подключении к docker-образу спарка, много вариантов перепробовал, порты 8080, 7070 открыты, разные настройки адреса передавал, все время большой лог ошибок и в конце:\n",
        "WARN StandaloneAppClient$ClientEndpoint: Drop UnregisterApplication(null) because has not yet connected to master\n",
        "\n",
        "на одном из форумов в итоге вычитал, что возможно проблема в разных версиях java на машине и в контейнере, но сил моральных уже не осталось\n",
        "\n",
        "через консоль прекрасно подключается к контейнеру"
      ],
      "metadata": {
        "id": "w3sK--DAJ84D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Само решение на pyspark ниже:"
      ],
      "metadata": {
        "id": "L8C5wyogMU5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = sc.TextFile('movies.csv')"
      ],
      "metadata": {
        "id": "UeQt0gI_LYHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = ['The', 'In', 'I', 'Mr.', 'a']"
      ],
      "metadata": {
        "id": "mqmbq2oZMglP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(\n",
        " data.map(lambda x: (x.split(',')[1].split(' ')[0], 1))\n",
        "     .filter(lambda x: x[0] not in stop_words)\n",
        "     .reduceByKey(lambda a, b: a + b) \\\n",
        "     .takeOrdered(15, lambda x: -x[1])\n",
        ")"
      ],
      "metadata": {
        "id": "SxErh54BLfVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rbykC4fTMSLg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}